#!/usr/bin/env python2.6

from os import path
import sys
import time
import re
import urllib2
import subprocess
from xml.sax.saxutils import escape

TPL_URL = "https://metricmgr.cern.ch/api/v2/mix/production/yaml/"
HOSTSCMD = "curl -s -u : --negotiate -H 'Accept: application/json' -k 'https://judy.cern.ch:9081//v3/facts/hostgroup?query=%5B%22%7E%22%2C+%22value%22%2C+%22vocms%2Fcmsweb%22%5D'" #query=["~","value","vocms/cmsweb"]
ALARMCMD = "curl -s -u : --negotiate -H 'Accept: application/json' -k 'https://judy.cern.ch:9081//v3/nodes/%s.cern.ch/facts?query=%%5B%%22%%7E%%22%%2C+%%22name%%22%%2C+%%22alarmed%%22%%5D' | grep value" #query=["~","name","alarmed"]
LEMONCMD = 'lemon-cli --script-mode -s -n "%s" -m "%s"'
LEMON_EXPIRED = 86400 # time in seconds to consider lemon feeds as expired

XML_TEMPLATE = """\
<?xml version="1.0" encoding="utf-8" ?>
  <serviceupdate xmlns="http://sls.cern.ch/SLS/XML/update">

    <id>%(slsid)s</id>
    <availability>%(avail)i</availability>
    <timestamp>%(tstamp)s</timestamp>
    <availabilitydesc>
      %(availdesc)s
    </availabilitydesc>
    <contact>
      %(contact)s
    </contact>
    <webpage>
      %(webpage)s
    </webpage>
    <availabilityinfo>%(availinfo)s</availabilityinfo>
    <lemon>
      %(hostlist)s
    </lemon>
    <notes>
      %(notes)s
    </notes>
    <data>
      %(data)s
    </data>
  </serviceupdate>
"""

HOSTS = []

hosts = subprocess.Popen(HOSTSCMD,stdout=subprocess.PIPE,shell=True).stdout.read()
hosts = re.findall('vocms[0-9]+',hosts)

for host in hosts:
  if not "false" in subprocess.Popen(ALARMCMD % host,stdout=subprocess.PIPE,shell=True).stdout.read(): # ignore production machines in maintenance
    HOSTS.append(host)

def spit_xml(feedname, lemonfeeds, name_id, isexcept, xml_out_dir):
  avail = 100
  availinfo = 0
  hostlist = set()
  mnames = set()
  numericvalue="\n      "

  failed=""
  for f in lemonfeeds.values():
    host,id,tstamp,v = f.split(" ",3)

    hostlist.add(host)
    mnames.add('cmsweb_'+name_id[id])
    if isexcept[id]:
      state, code, msg = v.split(" ",2)
      if int(state) == 1 and code in ['000', '135']:
        avail = 0
        availinfo += 1
        failed += "<textvalue>" + escape(f.strip()) + "</textvalue>\n      "
    else:
      numericvalue += "<numericvalue name=\"%s %s\">%s</numericvalue>\n      " \
          % (host, name_id[id].replace(feedname+'_','',1), v.split(" ")[0].replace('_empty_', '0'))

  if not failed:
    failed = "<textvalue>none</textvalue>"

  hl = ""
  for host in hostlist:
    hl += "<host>"+host+"</host>\n      "

  mn = ""
  for mname in mnames:
    mn += mname+"\n      "

  data =  "<textvalue>Hosts: " + str(" ").join(hostlist) + "</textvalue>\n      "
  data += "<textvalue>Detected alarms:</textvalue>\n      "
  data += failed.strip(" \n")
  data += numericvalue

  f=open(path.join(xml_out_dir,"sls_cmsweb_"+feedname+".xml"),"wt")
  f.write(XML_TEMPLATE % {
    'slsid': "cmsweb_"+feedname,
    'avail': avail,
    'availinfo': "Found " + str(availinfo) + " exception(s).",
    'availdesc': "Availability is 0% if there exist a lemon alarm in any of\n      the CMSWEB machines running this service, 100% otherwise.",
    'contact': "cms-service-webtools@cern.ch",
    'webpage': "https://cern.ch/cms-http-group/ops-trouble.html",
    'tstamp': time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime()),
    'hostlist': hl.strip(" \n"),
    'notes': "This SLS is a mapping from the following lemon metrics/exceptions:\n      " + mn.strip(),
    'data': data.strip(" \n")
  })
  f.close()

  return (feedname, avail)

def aggregate_xml(feeds_availability, xml_out_dir):
  avail = 0
  services = []
  failedservices = []
  nfailedservices = 0

  for (n, a) in feeds_availability:
    avail += a
    services.append(n)
    if a < 100:
      failedservices.append("<textvalue>" + n + "</textvalue>")
      nfailedservices += 1

  avail /= len(services)

  if nfailedservices == 0:
    failedservices.append("<textvalue>none</textvalue>")

  hl = ""
  for host in HOSTS:
    hl += "<host>"+host+"</host>\n      "

  data =  "<textvalue>Hosts: " + str(" ").join(HOSTS) + "</textvalue>\n      "
  data += "<textvalue>Failed services:</textvalue>\n      "
  data += str("\n      ").join(failedservices) + "\n"
  data += "      <numericvalue name=\"Failed Services\">" + str(nfailedservices) + "</numericvalue>"

  f=open(path.join(xml_out_dir,"sls_cmsweb.xml"),"wt")
  f.write(XML_TEMPLATE % {
    'slsid': "cmsweb",
    'avail': avail,
    'availinfo': "Found " + str(nfailedservices) + " service(s) with exceptions.",
    'availdesc': "Availability represents the percentage of services working properly on CMSWEB.\n      Any value below 100% represents a critical issue!",
    'contact': "cms-service-webtools@cern.ch",
    'webpage': "https://cern.ch/cms-http-group/ops-trouble.html",
    'tstamp': time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime()),
    'hostlist': hl.strip(" \n"),
    'notes': "This SLS is a general mapping from the following services:\n      " + str("\n      ").join(services),
    'data': data
  })
  f.close()

def build_metric_ids():
  name_ids = {}
  idlist = ""
  isexcept = {}
  metrics_page = urllib2.urlopen(TPL_URL).read()
  
  # Exceptions and DQM special metrics
  x = re.findall('lemon_([0-9]+):\n.*exception.cmsweb_(.*)\n',metrics_page)
  y = re.findall('lemon_([0-9]+):\n.*cmsweb_(dqm_[^_]*_agents_import_queue)\n',metrics_page)
  for (id,name) in x+y:
    name_ids[id] = name
    name_ids[name] = id
    idlist += id + " "
    isexcept[id] = (id,name) in x
  
  return (name_ids,idlist.strip(),isexcept)

if __name__ == "__main__":
  if len(sys.argv) != 2:
    print "Syntax: %s <xml_output_dir>" % sys.argv[0]
    sys.exit(1)
  xml_out_dir = sys.argv[1]

  (name_id, idlist, isexcept) = build_metric_ids()
  feeds={}

  cmd = LEMONCMD % (str(" ").join(HOSTS), idlist)
  p=subprocess.Popen(cmd,stdout=subprocess.PIPE, stderr=subprocess.PIPE,shell=True)
  for line in p.stdout:
    host,id,tstamp,v = line.split(" ",3)

    # lemonfeeds older then LEMON_EXPIRED seconds are considered
    # feeds from deactivated exceptions, so ignore
    if int(tstamp) + LEMON_EXPIRED > int(time.time()):
       feedname = re.search('(.*?)_',name_id[id]).group(1)
       f = feeds.get(feedname,{})
       f[host+':'+id]=line
       feeds[feedname] = f

  err = p.stderr.read()
  if err:
    print err

  aggregate = []
  for (k,v) in feeds.items():
    aggregate.append(spit_xml(k,v,name_id,isexcept,xml_out_dir))

  aggregate_xml(aggregate, xml_out_dir)

  sys.exit(0)
