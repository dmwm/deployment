#!/bin/sh

##H Usage: manage ACTION [ARG] [SECURITY-STRING]
##H
##H Available actions:
##H   help            show this help
##H   version         get current version of the service
##H   status          show current service's status
##H   sysboot         start server from crond if not running
##H   restart         (re)start the service
##H   start           (re)start the service
##H   stop            stop the service
##H   pushapps        push couch applications
##H   pushreps        push couch replications
##H   updatecouchapps pull new couch applications from WMCore repo
##H   compact         compact database ARG
##H   compactviews    compact database views for design doc ARG ARG
##H   cleanviews      clean view named ARG
##H   backup          rsync databases to ARG (i.e. [user@]host:path)
##H   archive         archive backups to ARG area in castor
##H
##H For more details please refer to operations page:
##H   https://twiki.cern.ch/twiki/bin/view/CMS/CouchDB

[ $(id -un) != cmsweb -o "$1" = "backup" -o "$1" = "archive" ] ||
  { echo "ERROR: please use another account" 1>&2; exit 1; }

case $(uname) in Darwin )
  md5sum() { md5 -r ${1+"$@"}; }
  ;;
esac

ME=$(basename $(dirname $0))
TOP=$(cd $(dirname $0)/../../.. && pwd)
ROOT=$(cd $(dirname $0)/../.. && pwd)
CFGDIR=$(cd $(dirname $0) && pwd)
LOGDIR=$TOP/logs/$ME
STATEDIR=$TOP/state/$ME
KEYFILE=$ROOT/auth/$ME/hmackey.ini
COLOR_OK="\\033[0;32m"
COLOR_WARN="\\033[0;31m"
COLOR_NORMAL="\\033[0;39m"
PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/kerberos/bin
export STAGE_HOST=${STAGE_HOST:-castorcms}
export STAGE_SVCCLASS=archive

EXCEPTIONS="wmstats"

. $ROOT/apps/$ME/etc/profile.d/init.sh

# Start service conditionally on crond restart.
sysboot()
{
  if couchdb -p $STATEDIR/couchdb.pid -s; then :; else
    start
  fi
}

# Start the service.
start()
{
  cd $STATEDIR
  couchdb -A $CFGDIR/ -a $KEYFILE -b \
    -o /dev/null \
    -e $LOGDIR/$(date +%Y%m%d-%H%M%S).stderr \
    -p $STATEDIR/couchdb.pid </dev/null >/dev/null 2>&1

  push_apps
  replications push
}

# Stop the service.
stop()
{
  couchdb -d -p $STATEDIR/couchdb.pid
}

# Check if the server is running.
status()
{
  couchdb -p $STATEDIR/couchdb.pid -s

  curl -s localhost:5984 | grep -q '"version":"1.[0-9.]*"' ||
    { echo "CouchDB is not correctly responding to requests"; return; }

  local TASKS=$(curl -s localhost:5984/_active_tasks)
  [ "$TASKS" = '[]' ] && TASKS="No active tasks (e.g. compactions)"
  echo $TASKS

  replications status
}

# When a view is changed, such as a new app version is deployed,
# invoke this to clean up the views in that database.
clean_views()
{
  local database=$1
  [ -n "$database" ] ||
    { echo "You must specify the database you wish to clean the views "; exit 1; }

  curl -s -H "Content-Type: application/json" -X POST http://localhost:5984/$database/_view_cleanup | \
       grep -q '{"ok":true}' ||
    { echo "An error occured while cleaning the views. Please look in the CouchDB logs."; exit 3; }
}

# Push applications from staging area into couchdb.
push_apps()
{
  local couchapps_path="/data/srv/state/couchdb/stagingarea/couchapps"

  if [[ ! -d $couchapps_path ]]; then
    echo "Couchapps not found. Installing from latest WMCore tag."
    update_couchapps "latest"
  fi

  n=0 started=false
  while [ $n -le 100 ]; do
    couchdb -p $STATEDIR/couchdb.pid -s &> /dev/null &&
      curl -s localhost:5984 | grep -q '"version":"1.[0-9.]*"' && 
      started=true && break
    echo "waiting for couchdb..."
    sleep 1
    n=$(expr $n + 1)
  done

  if $started; then
    # acdc server
    couchapp push -p $couchapps_path/ACDC -c http://localhost:5984/acdcserver
    couchapp push -p $couchapps_path/GroupUser -c http://localhost:5984/acdcserver

    # reqmgr2
    couchapp push -p $couchapps_path/ReqMgrAux -c http://localhost:5984/reqmgr_auxiliary
    couchapp push -p $couchapps_path/ReqMgr -c http://localhost:5984/reqmgr_workload_cache
    couchapp push -p $couchapps_path/ConfigCache -c http://localhost:5984/reqmgr_config_cache

    # reqmon
    couchapp push -p $couchapps_path/WorkloadSummary -c http://localhost:5984/workloadsummary
    couchapp push -p $couchapps_path/LogDB -c http://localhost:5984/wmstats_logdb
    couchapp push -p $couchapps_path/WMStats -c http://localhost:5984/wmstats
    couchapp push -p $couchapps_path/WMStatsErl -c http://localhost:5984/wmstats
    couchapp push -p $couchapps_path/WMStatsErl1 -c http://localhost:5984/wmstats
    couchapp push -p $couchapps_path/WMStatsErl2 -c http://localhost:5984/wmstats
    couchapp push -p $couchapps_path/WMStatsErl3 -c http://localhost:5984/wmstats
    couchapp push -p $couchapps_path/WMStatsErl4 -c http://localhost:5984/wmstats
    couchapp push -p $couchapps_path/WMStatsErl5 -c http://localhost:5984/wmstats
    couchapp push -p $couchapps_path/WMStatsErl6 -c http://localhost:5984/wmstats
    couchapp push -p $couchapps_path/WMStatsErl7 -c http://localhost:5984/wmstats

    # t0_reqmon
    couchapp push -p $couchapps_path/T0Request -c http://localhost:5984/t0_request
    couchapp push -p $couchapps_path/WorkloadSummary -c http://localhost:5984/t0_workloadsummary
    couchapp push -p $couchapps_path/LogDB -c http://localhost:5984/t0_logdb
    couchapp push -p $couchapps_path/WMStats -c http://localhost:5984/tier0_wmstats
    couchapp push -p $couchapps_path/WMStatsErl -c http://localhost:5984/tier0_wmstats
    couchapp push -p $couchapps_path/WMStatsErl1 -c http://localhost:5984/tier0_wmstats
    couchapp push -p $couchapps_path/WMStatsErl2 -c http://localhost:5984/tier0_wmstats
    couchapp push -p $couchapps_path/WMStatsErl3 -c http://localhost:5984/tier0_wmstats
    couchapp push -p $couchapps_path/WMStatsErl4 -c http://localhost:5984/tier0_wmstats
    couchapp push -p $couchapps_path/WMStatsErl5 -c http://localhost:5984/tier0_wmstats
    couchapp push -p $couchapps_path/WMStatsErl6 -c http://localhost:5984/tier0_wmstats
    couchapp push -p $couchapps_path/WMStatsErl7 -c http://localhost:5984/tier0_wmstats

    # workqueue
    couchapp push -p $couchapps_path/WorkQueue -c http://localhost:5984/workqueue
    couchapp push -p $couchapps_path/WorkQueue -c http://localhost:5984/workqueue_inbox

    # clean views
    local databases="acdcserver reqmgr_auxiliary reqmgr_workload_cache reqmgr_config_cache workloadsummary
                    wmstats_logdb wmstats t0_request t0_workloadsummary t0_logdb tier0_wmstats"

    for DB in $databases; do
      clean_views $DB
    done
  else
    echo "couchdb did not start, not pushing application"
    exit 1
  fi
}

update_couchapps()
{
  local WMCORE_TAG=$1
  [ -n $WMCORE_TAG ] ||
    { echo "WMCore tag not provided. Please provide a WMCore tag."; exit 1; }

  local couchapps_dir=/data/srv/state/couchdb/stagingarea
  local tmp_dir=$couchapps_dir/tmp

  # clean up and recreate $tmp_dir
  rm -rf $tmp_dir
  mkdir -p $tmp_dir

  pushd $tmp_dir

  if [[ $WMCORE_TAG == "latest" ]]; then
    WMCORE_TAG=$(curl https://api.github.com/repos/dmwm/WMCore/releases/latest | grep -Po '"tag_name": "\K.*?(?=")')
  fi

  echo "Pulling couchapps version $1 from Github..."
  wget https://github.com/dmwm/WMCore/archive/refs/tags/${WMCORE_TAG}.tar.gz ||
    { echo "Error pulling couchapps version $1 from Github"; exit 3; }

  tar --strip-components=2 -xzf ${WMCORE_TAG}.tar.gz WMCore-$WMCORE_TAG/src/couchapps ||
    { echo "Error extracting couchapps tarball"; exit 3; }

  # grab external dependencies for reqmon/t0_reqmon
  echo "Pulling additional reqmon and t0_reqmon dependencies..."
  cp -R $tmp_dir/couchapps/couchskel/vendor $tmp_dir/couchapps/WMStats
  mkdir -p $tmp_dir/couchapps/WMStats/vendor/{jquery,datatables}/_attachments

  # jquery-ui.min.js
  echo "Downloading jquery-ui.min.js..."
  wget https://ajax.googleapis.com/ajax/libs/jqueryui/1.8.18/jquery-ui.min.js ||
    { echo "Error downloading jquery-ui.min.js"; exit 3; }
  cp jquery-ui.min.js $tmp_dir/couchapps/WMStats/vendor/jquery/_attachments/jquery-ui.min.js

  # jquery.min.js
  echo "Downloading jquery.min.js..."
  wget http://code.jquery.com/jquery-1.7.2.min.js ||
    { echo "Error downloading jquery-1.7.2.min.js"; exit 3; }
  cp jquery-1.7.2.min.js $tmp_dir/couchapps/WMStats/vendor/jquery/_attachments/jquery.min.js

  # Datatables
  echo "Downloading Datatables..."
  wget http://datatables.net/releases/DataTables-1.9.1.zip ||
    { echo "Error downloading Datatables-1.9.1.zip"; exit 3; }
  unzip DataTables-1.9.1.zip &> /dev/null
  cp DataTables*/{media/js/jquery.dataTables.min,extras/ColVis/media/js/ColVis.min}.js $tmp_dir/couchapps/WMStats/vendor/datatables/_attachments

  echo "Removing old couchapps..."
  rm -rf $couchapps_dir/couchapps &> /dev/null

  echo "Installing new couchapps..."
  mv couchapps $couchapps_dir

  popd
  echo "Cleaning up!"
  rm -rf $tmp_dir
}

replications()
{
  [ "$1" = "push" ] && local status=false || local status=true
  local all_reps=$(curl -s localhost:5984/_replicator/_all_docs?include_docs=true \
                   | grep '^{"id":"[^_]' | awk -F\" '{print $4,$14,$28,$32,$38,$42}')
  local req_reps=$(cat $STATEDIR/replication/* 2>/dev/null || echo "")

  if [ -n "$all_reps" ]; then
    echo "$all_reps" | while read ID REV SRC DST FILTER STATE; do
      if echo "$req_reps" | grep -q "$SRC $DST $FILTER"; then
        echo "Replication 'id=$ID source=$SRC target=$DST filter=$FILTER' $STATE."
      else
        echo "Replication 'id=$ID source=$SRC target=$DST filter=$FILTER' unknown."
        if ! $status; then
          echo -n "Removing it... "
          curl -s -X DELETE localhost:5984/_replicator/$ID?rev=$REV
        fi
      fi
    done
  fi

  if [ -n "$req_reps" ]; then
    local IDS=$(echo "$all_reps" | awk '{print $1}')
    echo "$req_reps" | while read SRC DST FILTER; do
      local ID=$(echo "$SRC $DST $FILTER" | md5sum | awk '{print $1}')
      if ! echo "$IDS" | grep -q "$ID"; then
        echo "Replication 'id=$ID source=$SRC target=$DST filter=$FILTER' not pushed."
        if ! $status; then
          echo -n "Pushing it... "
          curl -s -X PUT localhost:5984/_replicator/$ID \
               -d "{\"source\":\"$SRC\", \"target\":\"$DST\", \"continuous\":true, \"filter\":\"$FILTER\"}"
        fi
      fi
    done
  fi
}

# Trigger database compaction. 
# - If "all", then compact ALL databases.
# - If "all_but_exceptions", then compact all views but the ones listed in EXCEPTIONS
# - Otherwise, the database must be provided 
compact()
{
  local database=$1
  [ -n "$database" ] ||
    { echo "You must specify a database to compact"; exit 3; }

  if [ "$database" = all -o "$database" = all_but_exceptions ]; then
    for db in $STATEDIR/database/[^_]*.couch; do
      [ -f $db ] || continue
      db=${db##*/}
      db=${db%.couch}
      if [[ $EXCEPTIONS == *$db* && "$database" = all_but_exceptions ]]; then
        continue
      fi
      compact_database $db
    done
  else
    compact_database $database
  fi
}

compact_database()
{
  local database=$1
  curl -s localhost:5984/$database | grep -q '"compact_running":true' &&
    { echo "$database is already compacting"; exit 5; }

  curl -s -H "Content-Type: application/json" -X POST http://localhost:5984/$database/_compact | \
        grep -q '{"ok":true}' ||
    { echo "An error occured triggering compaction. Please look in the CouchDB logs."; exit 7; }
}

# Trigger view compaction.
# - If "all", then compact ALL views
# - If "all_but_exceptions", then compact all views but the ones listed in EXCEPTIONS
# - Otherwise, the database and designdoc must be provided
compact_views()
{
  local database=$1
  local designdoc=$2
  [ -n "$database" ] ||
    { echo "You must specify a database to compact its views"; exit 3; }
  [ -n "$designdoc" ] ||
    { echo "You must specify a design doc to compact its views"; exit 3; }

  if [ "$database" = all -o "$database" = all_but_exceptions ]; then
    for db in $STATEDIR/database/[^_]*.couch; do
      [ -f $db ] || continue
      db=${db##*/}
      db=${db%.couch}
      if [[ $EXCEPTIONS == *$db* && "$database" = all_but_exceptions ]]; then
        continue
      fi
      curl -s "localhost:5984/$db/_all_docs?startkey=%22_design%22&endkey=%22_design/zzzzzzzz%22" |
        awk -F\" '/"id":"_design/ {print $4}' |
        while read dbview; do
          compact_view $db ${dbview#*/}
	done
    done
  elif [ "$designdoc" = all ]; then
    curl -s "localhost:5984/$database/_all_docs?startkey=%22_design%22&endkey=%22_design/zzzzzzzz%22" |
      awk -F\" '/"id":"_design/ {print $4}' |
      while read dbview; do
        compact_view $database ${dbview#*/}
      done
  else
    compact_view $database $designdoc
  fi
}

# Trigger single view compaction
compact_view()
{
  local database=$1
  local designdoc=$2

  curl -s localhost:5984/$database/_design/$designdoc/_info | grep -q '"compact_running":true' &&
    { echo "$database/$designdoc is already compacting"; exit 5; }

  curl -s -H "Content-Type: application/json" -X POST http://localhost:5984/$database/_compact/$designdoc | \
        grep -q '{"ok":true}' ||
    { echo "An error occured triggering view compaction. Please look in the CouchDB logs."; exit 7; }
}

# Rsync couchdb databases to elsewhere (can be used to restore a backup too)
backup()
{
  local hostdir=$1
  [ -n "$hostdir" ] ||
    { echo "You must specify a destination [user@]host:path."; exit 9; }
  #ionice -c3 rsync --delete --delete-excluded --exclude "*.compact*" -au -e 'ssh -c arcfour' $STATEDIR/database/ $hostdir/ ||
   ionice -c3 rsync --delete --delete-excluded --exclude "*.compact*" -au -e 'ssh -c aes128-ctr' $STATEDIR/database/ $hostdir/ ||

    { echo "failed to synchronise databases to $hostdir: $?" 1>&2; exit 11; }
}

# Archive couchdb backups to castor
archive()
{
  local archdir=$1
  klist -s ||
    { echo "You must have a valid kerberos token to run the archive." 1>&2; exit 20; }
  rfstat $archdir >/dev/null ||
    { echo "Could not stat $archdir in the castor archive" 1>&2; exit 19; }

  echo "Checking for couchdb archives not yet staged out to tape:"
  stager_qry -M $archdir | grep couchdb | grep -v STAGED || echo "all staged out."

  echo
  echo "Starting to archive couchdb backups on $(date)"
  for bkp in $STATEDIR/backup/*; do
    [ -d $bkp ] || continue;
    tarfile=couchdb_${bkp##*/}_$(date +%Y%m%d-%H%M).tar
    echo "$archdir/$tarfile"
    tar cf - -C $bkp . | rfcp - $archdir/$tarfile &
  done
  wait;
  [ -n "$tarfile" ] && echo "Archive copy to castor completed on $(date)." ||
    echo "No backups found on $STATEDIR/backup. Nothing to archive."

  #FIXME: do some sanity checks on castor to make sure new archives are genuine

  # Cleanup old archives
  for bkp in $STATEDIR/backup/*; do
    [ -d $bkp ] || continue;
    tarprefix=couchdb_${bkp##*/}
    since=$(date --date='3 months ago' +%Y%m%d)
    echo
    echo "Cleaning old archives for $tarprefix:"
    for f in $(nsls $archdir|grep $tarprefix); do
      if [ $(echo -n $f | cut -d_ -f3| cut -d- -f1) -lt $since ]; then
        echo $archdir/$f
        rfrm $archdir/$f
      fi
    done
  done

  echo
  echo "Archive procedure done."
}

# Verify the security string.
check()
{
  CHECK=$(echo "$1" | md5sum | awk '{print $1}')
  if [ $CHECK != 94e261a5a70785552d34a65068819993 ]; then
    echo "$0: cannot complete operation, please check documentation." 1>&2
    exit 2;
  fi
}

# Main routine, perform action requested on command line.
case ${1:-status} in
  sysboot )
    sysboot
    ;;

  start | restart )
    check "$2"
    stop
    sleep 1
    start
    ;;

  status )
    status
    ;;

  stop )
    check "$2"
    stop
    ;;

  pushapps )
    check "$2"
    push_apps
    ;;

  pushreps )
    check "$2"
    replications push
    ;;

  updatecouchapps )
    check "$3"
    update_couchapps $2
    ;;

  compact )
    check "$3"
    compact $2
    ;;

  compactviews )
    check "$4"
    compact_views $2 $3
    ;;

  cleanviews )
    check "$3"
    clean_views $2
    ;;

  backup )
    check "$3"
    backup $2
    ;;

  archive )
    check "$3"
    archive $2
    ;;

  help )
    perl -ne '/^##H/ && do { s/^##H ?//; print }' < $0
    ;;

  version )
    echo "$COUCHDB_VERSION"
    ;;

  * )
    echo "$0: unknown action '$1', please try '$0 help' or documentation." 1>&2
    exit 1
    ;;
esac
