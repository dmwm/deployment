#!/bin/sh

##H Usage 1: manage [options] ACTION [ARG] [SECURITY-STRING]
##H
##H Available actions:
##H   help            show this help
##H   version         get current version of the service
##H   status          show current service's status
##H   dstatus         show current service's detailed status
##H   sysboot         start server from crond if not running
##H   restart         (re)start the service
##H   start           (re)start the service
##H   stop            stop the service
##H   compile         refresh render plugins
##H   indexbackup     backup the index to CASTOR
##H   zipbackup       backup new root files to CASTOR
##H   zipbackupcheck  check if the backup of the root files to castor was successful
##H
##H Usage 2: manage [options] ACTION COMPONENTs [SECURITY-STRING]
##H COMPONENTs: webserver collector renderer logger agents
##H
##H   xstatus     show status for COMPONENTs
##H   xdstatus    show detailed status for COMPONENTs
##H   xstart      (re)start COMPONENTs
##H   xrestart    (re)start COMPONENTs
##H   xstop       stop COMPONENTs
##H
##H Options:
##H -f flavor     Overide default flavor selected by server and domain.
##H               Flavors are: {online, offline, relval, dev}
##H For more details please refer to operations page:
##H   https://twiki.cern.ch/twiki/bin/view/CMS/DQMGui

echo_e=-e
bsdstart=bsdstart
case $(uname) in Darwin )
  md5sum() { md5 -r ${1+"$@"}; }
  echo_e=
  bsdstart=start
  ;;
esac

ME=$(basename $(dirname $0))
TOP=$(cd $(dirname $0)/../../.. && pwd)
ROOT=$(cd $(dirname $0)/../.. && pwd)
CFGDIR=$(dirname $0)
LOGDIR=$TOP/logs/$ME
STATEDIR=$TOP/state/$ME
HOST=$(hostname -s | tr '[:upper:]' '[:lower:]')
DOMAIN=$(hostname -d | tr '[:upper:]' '[:lower:]')
COLOR_OK="\\033[0;32m"
COLOR_WARN="\\033[0;31m"
COLOR_NORMAL="\\033[0;39m"
CONFIGS=
QUIET=false
FLAVOR=dev
PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/kerberos/bin
PYTHONPATH=${ROOT}/auth/${ME}:${PYTHONPATH}

. $ROOT/apps/dqmgui/128/etc/profile.d/env.sh

export QUIET_ASSERT=a
export X509_CERT_DIR=/etc/grid-security/certificates
export X509_USER_PROXY=$STATEDIR/proxy/proxy.cert
export X509_USER_CERT=$X509_USER_PROXY
export X509_USER_KEY=$X509_USER_PROXY
export STAGE_HOST=${STAGE_HOST:-castorcms}
export RFIO_USE_CASTOR_V2=YES
export STAGE_SVCCLASS=archive

# Set Flavor for HOST:DOMAIN
case $HOST:$DOMAIN in
  # Anything in the CMS network, will be automatically Online
  *:cms )       FLAVOR=online ;;
  # On the production machines in the CERN network, flavor is based on the
  # machine and they get an alternate user
  vocms0138:* ) FLAVOR=offline;                ALTERNATIVE_USER='cmsweb' ;;
  vocms0139:* ) FLAVOR=relval;                 ALTERNATIVE_USER='cmsweb' ;;
  vocms0131:* ) FLAVOR=offline-relval-testing; ALTERNATIVE_USER='cmsweb' ;;
  # Private instances get the dev flavor, unless specified differently
  *:cern.ch )   FLAVOR=dev;;
esac

# Select the right configuration based on FLAVOR
getconfigs(){
case $FLAVOR in
  online )                 CONFIGS="online";;
  offline )                CONFIGS="offline";;
  relval )                 CONFIGS="relval";;
  offline-relval-testing ) CONFIGS="offline relval dev";;
  dev )                    CONFIGS="dev";;
esac
}

message()
{
  $QUIET && return
  case $1 in
    -n ) shift; printf "%s" "$*" ;;
    * ) echo ${1+"$@"} ;;
  esac
}

# Procedure witch will check if a process is not already running before starting it
refuseproc()
{
  local title="$1" pat="$2" reason="$3"
  if [ $(pgrep -u $(id -u) -f "$pat" | wc -l) != 0 ]; then
    echo "$title: $reason because processes matching '$pat' are still running" 1>&2
    exit 4
  fi
}

statproc()
{
  local user=$(id -u) title pat
  while [ $# -ge 1 ]; do
    case $1 in
      -u ) user=$2; shift; shift ;;
      -- ) shift; break ;;
      -* ) echo "$0 (statproc): bad option '$1'" 1>&2; exit 1 ;;
      *  ) break ;;
    esac
  done
  title="$1" pat="$2"
  pid=$(pgrep -u $user -f "$pat" | sort -n)
  if [ X"$pid" = X ]; then
    message $echo_e "$title is ${COLOR_WARN}NOT RUNNING${COLOR_NORMAL}."
  else
    message $echo_e "$title is ${COLOR_OK}RUNNING${COLOR_NORMAL}, PID" $pid
  fi
}

sdproc()
{
  local user=$(id -u) title pat
  while [ $# -ge 1 ]; do
    case $1 in
      -u ) user=$2; shift; shift ;;
      -- ) shift; break ;;
      -* ) echo "$0 (sdproc): bad option '$1'" 1>&2; exit 1 ;;
      *  ) break ;;
    esac
  done
  title="$1" pat="$2"
  local title="$1" pat="$2"
  message $echo_e "${COLOR_OK}${newline}${title}:${COLOR_NORMAL}"
  pgrep -u $(id -u) -f "$pat" | xargs -r ps -o pid=,$bsdstart=,args= |
    perl -p -e 'use Term::ANSIColor qw(:constants);s/^/  /; END { $. || print RED,"  (none running)", RESET, "\n" } ' |
    sort -k 4
  newline="\n"
}


killproc()
{
  local T title pat nextmsg
  T=1 title="$1" pat="$2"
  nextmsg="${newline}Stopping ${title}:"
  for pid in $(pgrep -u $(id -u) -f "$pat" | sort -rn); do
    psline=$(ps -o pid=,$bsdstart=,args= $pid |
             perl -n -e 'print join(" ", (split)[0..4])')
    [ -n "$nextmsg" ] && { message $echo_e "$nextmsg"; nextmsg=; }
    message -n "Stopping $pid ($psline):"
    for sig in TERM TERM QUIT KILL; do
      message -n " SIG$sig"
      kill -$sig $pid
      sleep 1
      [ $(ps -o pid= -p $pid | wc -l) = 0 ] && break
      sleep $T
      T=$(expr $T \* 2)
      [ $(ps -o pid= -p $pid | wc -l) = 0 ] && break
    done
    message
    newline="\n"
  done
}

startagent()
{
  local edition=
  case $1 in
    -e ) edition=$2; shift;shift
  esac
  local logstem=${1}; shift
  ([ ! -z $edition ] && source $ROOT/apps/dqmgui/$edition/etc/profile.d/env.sh
   set -x; date; exec "$@") </dev/null 2>&1 | rotatelogs $LOGDIR/$logstem-%Y%m%d.log 86400 >/dev/null 2>&1 &
}

# Start service conditionally on crond restart.
sysboot()
{
  if [ $(pgrep -u $(id -u) -f "[/]monGui $CFGDIR" | wc -l) = 0 ]; then
    start
  fi
}

# Start the service.
start()
{
  cd $STATEDIR
  message "starting $ME/$FLAVOR ${1:-(default)}"

  # First start webserver
  # This is the core of the GUI, so it's always started
  start_webserver
  # Then start agents
  # Depending on the machine, different agents will be started
  start_agents
  # Finally start collector
  # This is the part that can collect life data coming from CMSSW
  # It's mostly used in the Online world
  start_collector
}

start_webserver()
{
  case $HOST:${1:-webserver} in
    *:*webserver* )
      for CONFIG in $CONFIGS; do
        [ ! -d $STATEDIR/$CONFIG/ix128 ] && \
          (echo Creating index $STATEDIR/$CONFIG/ix128; visDQMIndex create $STATEDIR/$CONFIG/ix128)
        monControl start all from $CFGDIR/server-conf-$CONFIG.py
      done ;;
  esac
}

start_agents()
{
  case $HOST:${1:-agents} in
    ##### ONLINE: online server srv-c2f11-29-01
    # alias: dqm-prod-local
    # the first online server runs
    # - the only receive daemon in the online world, distributing to all the
    #   rest
    # - the import daemon
    # - the sound alert daemon
    # agent dropboxes are on a shared environment
    # note that no zip or backup daemons are run, root files from the online
    # are pulled from the offline and backed up there
    srv-c2f11-29-01:*agents* )
      start_agents_dqm_prod_local ;;
    ##### ONLINE: online server srv-c2f11-29-02
    # alias: dqm-prod-offsite
    # the second online server runs
    # - the import daemon
    # agent dropboxes are on a shared environment
    # note that no zip or backup daemons are run, root files from the online
    # are pulled from the offline and backed up there
    srv-c2f11-29-02:*agents* )
      start_agents_dqm_prod_offsite ;;
    ##### ONLINE: online server srv-c2f11-29-03
    # alias: dqm-integration
    # the playback online server runs
    # - the receive daemon
    # - the import daemon
    # agent dropboxes are local to the machine
    # nothing gets backed up
    srv-c2f11-29-03:*agents* )
      start_agents_dqm_integration ;;
    ##### ONLINE: online server srv-c2f11-29-04
    # alias: dqm-test
    # the second online server runs
    # - the import daemon
    # agent dropboxes are on a shared environment
    # nothing gets backed up
    srv-c2f11-29-04:*agents* )
      start_agents_dqm_test ;;
    ##### OFFLINE: offline server vocms0138
    # The offline server runs
    # - the standard receive and import daemons
    # - the quota and version control daemons
    # - the zip and zipfreeze daemons
    # - the online sync and create info daemon that copies root data from the
    #   online to offline
    # note that the agents to copy zip to castor, verify zip from castor and
    # copy index to castor run as tasks under acron.
    vocms0138:*agents* )
      start_agents_offline ;;
    ##### OFFLINE: Relval server vocms0139
    # The Relval server runs
    # - the standard receive and import daemons
    # - the quota and version control daemons
    # - the zip and zipfreeze daemons
    # Note that the agents to copy zip to Castor, verify zip from Castor and
    # copy index to Castor run as tasks under acron.
    vocms0139:*agents* )
      start_agents_relval ;;
    ##### OFFLINE: Test server vocms0131
    # This server runs 3 gui's in 3 flavors: dev, offline and relval
    # The test server runs
    # - the standard receive and import daemons
    # - the quota and version control daemons
    # Only for the dev flavor it runs:
    # - the zip and zipfreeze daemons
    # - the acron tasks that do the backups to Castor
    # We also keep a local backup of the index (rsynced by the import
    # daemon).
    vocms0131:*agents* )
      start_agents_offline_relval_test ;;
    ##### PRIVATE or DEVELOPMENT instances
    # The private or development servers run
    # - the standard receive and import daemons
    # - the quota and version control daemons
    *:*agents* )
      start_agents_local_development ;;
  esac
}

start_agents_dqm_prod_local()
{
  refuseproc "file agents" "visDQMIndex" "refusing to restart"
  D=online
  DQM_DATA=/dqmdata/dqm

  startagent $D/agent-receive \
    visDQMReceiveDaemon \
    $DQM_DATA/uploads \
    $DQM_DATA/repository/original \
    $DQM_DATA/agents/import-srv-c2f11-29-01 \
    $DQM_DATA/agents/import-srv-c2f11-29-02 \
    $DQM_DATA/agents/import-srv-c2f11-29-04

  startagent $D/agent-import-128 \
    visDQMImportDaemon \
    $DQM_DATA/agents/import-srv-c2f11-29-01 \
    $DQM_DATA/repository/original \
    $STATEDIR/online/ix128 \
    --rsync \
    --email broen.van.besien@cern.ch,marco.rovere@cern.ch

  startagent $D/agent-sound \
    visDQMSoundAlarmDaemon \
    http://localhost:8030/dqm/online \
    cmsdaqweb.cms \
    50555 600 2 \
    cms-dqm-oncall@cern.ch
}

start_agents_dqm_prod_offsite()
{
  refuseproc "file agents" "visDQMIndex" "refusing to restart"
  D=online
  DQM_DATA=/dqmdata/dqm

  startagent $D/agent-import-128 \
    visDQMImportDaemon \
    $DQM_DATA/agents/import-srv-c2f11-29-02 \
    $DQM_DATA/repository/original \
    $STATEDIR/online/ix128
}

start_agents_dqm_integration()
{
  refuseproc "file agents" "visDQMIndex" "refusing to restart"
  D=online
  DQM_DATA=$STATEDIR/online

  startagent $D/agent-receive \
    visDQMReceiveDaemon \
    $DQM_DATA/uploads \
    $DQM_DATA/data \
    $DQM_DATA/agents/register \

  startagent $D/agent-import-128 \
    visDQMImportDaemon \
    $DQM_DATA/agents/register \
    $DQM_DATA/data \
    $STATEDIR/online/ix128
}

start_agents_dqm_test()
{
  refuseproc "file agents" "visDQMIndex" "refusing to restart"
  D=online
  DQM_DATA=/dqmdata/dqm

  startagent $D/agent-import-128 \
    visDQMImportDaemon \
    $DQM_DATA/agents/import-srv-c2f11-29-04 \
    $DQM_DATA/repository/original \
    $STATEDIR/online/ix128
}

start_agents_offline()
{
  refuseproc "file agents" "visDQMIndex|[^/]zip +|OnlineSync|visDQMCreateInfo" "refusing to restart"
  for D in $CONFIGS; do
    D=${D}
    DQM_DATA=$STATEDIR/$D

    startagent $D/agent-receive \
      visDQMReceiveDaemon \
      $DQM_DATA/uploads \
      $DQM_DATA/data \
      $DQM_DATA/agents/register \
      $DQM_DATA/agents/zip

    startagent $D/agent-import-128 \
      visDQMImportDaemon \
      $DQM_DATA/agents/register \
      $DQM_DATA/data \
      $DQM_DATA/ix128 \
      --next $DQM_DATA/agents/qcontrol $DQM_DATA/agents/vcontrol \
      --rsync \
      --rsyncnext $DQM_DATA/agents/ixstageout \
      --email broen.van.besien@cern.ch,marco.rovere@cern.ch

    startagent $D/agent-qcontrol \
      visDQMRootFileQuotaControlDaemon \
      $DQM_DATA/agents/qcontrol \
      $DQM_DATA/agents/register \
      $DQM_DATA/data \
      $CFGDIR/rootfilequota-${D}-prod.py

    startagent $D/agent-vcontrol \
      visDQMRootFileVersionControlDaemon \
      $DQM_DATA/agents/vcontrol \
      $DQM_DATA/data

    startagent $D/agent-zip \
      visDQMZipDaemon \
      $DQM_DATA/agents/zip \
      $DQM_DATA/data \
      $DQM_DATA/zipped \
      $DQM_DATA/agents/freezer

    startagent $D/agent-zfreeze \
      visDQMZipFreezeDaemon \
      $DQM_DATA/agents/freezer \
      $DQM_DATA/zipped \
      7 \
      $DQM_DATA/agents/stageout

    startagent $D/agent-osync \
      visDQMOnlineSyncDaemon \
      -s https://cmsweb.cern.ch/dqm/online/data/browse/Original \
      -d 14400 \
      -n 50 \
      /dev/null \
      $DQM_DATA/data/OnlineData/original

    startagent $D/agent-coinfo \
      visDQMCreateInfoDaemon \
      $DQM_DATA/data/OnlineData \
      $DQM_DATA/agents/zip
  done
}

start_agents_relval()
{
  refuseproc "file agents" "visDQMIndex|[^/]zip +" "refusing to restart"
  for D in $CONFIGS; do
    D=${D}
    DQM_DATA=$STATEDIR/$D

    startagent $D/agent-receive \
      visDQMReceiveDaemon \
      $DQM_DATA/uploads \
      $DQM_DATA/data \
      $DQM_DATA/agents/register \
      $DQM_DATA/agents/zip

    startagent $D/agent-import-128 \
      visDQMImportDaemon \
      $DQM_DATA/agents/register \
      $DQM_DATA/data \
      $DQM_DATA/ix128 \
      --next $DQM_DATA/agents/qcontrol $DQM_DATA/agents/vcontrol \
      --rsync \
      --rsyncnext $DQM_DATA/agents/ixstageout \
      --email broen.van.besien@cern.ch,marco.rovere@cern.ch

    startagent $D/agent-qcontrol \
      visDQMRootFileQuotaControlDaemon \
      $DQM_DATA/agents/qcontrol \
      $DQM_DATA/agents/register \
      $DQM_DATA/data \
      $CFGDIR/rootfilequota-${D}-prod.py

    startagent $D/agent-vcontrol \
      visDQMRootFileVersionControlDaemon \
      $DQM_DATA/agents/vcontrol \
      $DQM_DATA/data

    startagent $D/agent-zip \
      visDQMZipDaemon \
      $DQM_DATA/agents/zip \
      $DQM_DATA/data \
      $DQM_DATA/zipped \
      $DQM_DATA/agents/freezer

    startagent $D/agent-zfreeze \
      visDQMZipFreezeDaemon \
      $DQM_DATA/agents/freezer \
      $DQM_DATA/zipped \
      7 \
      $DQM_DATA/agents/stageout
  done
}

start_agents_offline_relval_test()
{
  refuseproc "file agents" "visDQMIndex" "refusing to restart"
  for D in $CONFIGS; do
    D=${D}
    DQM_DATA=$STATEDIR/$D

    if [ "$D" = "dev" ]; then
      startagent $D/agent-receive \
        visDQMReceiveDaemon \
        $DQM_DATA/uploads \
        $DQM_DATA/data \
        $DQM_DATA/agents/register \
        $DQM_DATA/agents/zip

      startagent $D/agent-import-128 \
        visDQMImportDaemon \
        $DQM_DATA/agents/register \
        $DQM_DATA/data \
        $DQM_DATA/ix128 \
        --next $DQM_DATA/agents/qcontrol $DQM_DATA/agents/vcontrol \
        --rsync \
        --rsyncnext $DQM_DATA/agents/ixstageout \
        --email broen.van.besien@cern.ch,marco.rovere@cern.ch
      # We do the rsync, but only for the dev instance, it's propagated to the
      # agent dropbox to be backed up on Castor
    else
      startagent $D/agent-receive \
        visDQMReceiveDaemon \
        $DQM_DATA/uploads \
        $DQM_DATA/data \
        $DQM_DATA/agents/register

      startagent $D/agent-import-128 \
        visDQMImportDaemon \
        $DQM_DATA/agents/register \
        $DQM_DATA/data \
        $DQM_DATA/ix128 \
        --next $DQM_DATA/agents/qcontrol $DQM_DATA/agents/vcontrol \
        --rsync \
        --email broen.van.besien@cern.ch,marco.rovere@cern.ch
    fi

    startagent $D/agent-qcontrol \
      visDQMRootFileQuotaControlDaemon \
      $DQM_DATA/agents/qcontrol \
      $DQM_DATA/agents/register \
      $DQM_DATA/data \
      $CFGDIR/rootfilequota-${D}-test.py

    startagent $D/agent-vcontrol \
      visDQMRootFileVersionControlDaemon \
      $DQM_DATA/agents/vcontrol \
      $DQM_DATA/data

    if [ "$D" = "dev" ]; then
      startagent $D/agent-zip \
        visDQMZipDaemon \
        $DQM_DATA/agents/zip \
        $DQM_DATA/data \
        $DQM_DATA/zipped \
        $DQM_DATA/agents/freezer

      startagent $D/agent-zfreeze \
        visDQMZipFreezeDaemon \
        $DQM_DATA/agents/freezer \
        $DQM_DATA/zipped \
        7 \
        $DQM_DATA/agents/stageout
    fi
  done
}

start_agents_local_development()
{
  refuseproc "file agents" "visDQMIndex" "refusing to restart"
  for D in $CONFIGS; do
    D=${D}
    DQM_DATA=$STATEDIR/$D
    startagent $D/agent-receive \
      visDQMReceiveDaemon \
      $DQM_DATA/uploads \
      $DQM_DATA/data \
      $DQM_DATA/agents/register

    startagent $D/agent-import-128 \
      visDQMImportDaemon \
      $DQM_DATA/agents/register \
      $DQM_DATA/data \
      $DQM_DATA/ix128 \
      --next $DQM_DATA/agents/qcontrol $DQM_DATA/agents/vcontrol

    startagent $D/agent-qcontrol \
      visDQMRootFileQuotaControlDaemon \
      $DQM_DATA/agents/qcontrol \
      $DQM_DATA/agents/register \
      $DQM_DATA/data \
      $CFGDIR/rootfilequota-local-development.py

    startagent $D/agent-vcontrol \
      visDQMRootFileVersionControlDaemon \
      $DQM_DATA/agents/vcontrol \
      $DQM_DATA/data
  done
}

start_collector()
{
  # Note that the setup of the port to which a specific server is listening is
  # not done here, but instead in the specific server config file.
  case $FLAVOR:$HOST:${1:-collector} in
    # Online servers: Collector for the first one, no collector for the other two:
    online:srv-c2f11-29-01:*collector* )
      DQMCollector --listen 9090 </dev/null 2>&1 | rotatelogs $LOGDIR/$FLAVOR/collector-%Y%m%d.log 86400 >/dev/null 2>&1 & ;;
    online:srv-c2f11-29-02:*collector* ) ;;
    online:srv-c2f11-29-04:*collector* ) ;;
    # Playback server: Gets its own collector:
    online:srv-c2f11-29-03:*collector* )
      DQMCollector --listen 9090 </dev/null 2>&1 | rotatelogs $LOGDIR/$FLAVOR/collector-%Y%m%d.log 86400 >/dev/null 2>&1 & ;;
    # Rest/default: Standard collector:
    online:*:*collector* )
      DQMCollector --listen 9190 </dev/null 2>&1 | rotatelogs $LOGDIR/$FLAVOR/collector-%Y%m%d.log 86400 >/dev/null 2>&1 & ;;
    *:*:*collector* )
      DQMCollector --listen 8061 </dev/null 2>&1 | rotatelogs $LOGDIR/$FLAVOR/collector-%Y%m%d.log 86400 >/dev/null 2>&1 & ;;
  esac
}

# Stop the service.
# When starting, the order is: server - agents - collector
# When stopping, the order is: collector - agents - server
stop()
{
  message "stopping $ME/$FLAVOR ${1:-(default)}"
  # Collector
  case ${1:-collector} in *collector* )
    killproc "$ME collector" "DQMCollector" ;;
  esac
  # Agents
  case ${1:-agents} in *agents* )
    killproc "$ME file agents" "visDQM.*Daemon|visDQM.*Castor.*"
    # The visDQMZipCastorStager and visDQMZipCastorVerifier agents keep their
    # status in a persisted file. When we restart (and hence stop) these
    # agents we want these files to be deleted. Otherwise it would be as if
    # these processes would run for years and years, while it's probably a good
    # idea to reset them from time to time.
    for CONFIG in $CONFIGS; do
      rm -rf $STATEDIR/$CONFIG/agents/stageout/new.pickle
      rm -rf $STATEDIR/$CONFIG/agents/verify/state.pickle
    done ;;
  esac
  # Server (render processes are killed with the server)
  case ${1:-webserver} in *webserver* )
    for CONFIG in $CONFIGS; do
      monControl stop all from $CFGDIR/server-conf-$CONFIG.py
    done ;;
  esac
}

# Check if the server is running.
status()
{
  # Collector
  case ${1:-collector} in *collector* )
    statproc "$ME collector" "DQMCollector" ;;
  esac
  # Agents
  case ${1:-agents} in *agents* )
    statproc "$ME file agents" "visDQM.*Daemon|visDQM.*Castor.*|visDQMIndex|zip" ;;
  esac
  # Server
  case ${1:-webserver} in *webserver* )
    statproc "$ME webserver" "[/]monGui $CFGDIR" ;;
  esac
  # Part of the server are the render processes
  case ${1:-renderer} in *renderer* )
    statproc "$ME renderer" "visDQMRender" ;;
  esac
  # Extra thing to check: loggers
  case ${1:-logger} in *logger* )
    statproc "$ME loggers" "rotatelogs" ;;
  esac
}

# Give details of server components
detailstatus()
{
  # Collector
  case ${1:-collector} in *collector* )
    sdproc "$ME collector" "DQMCollector" ;;
  esac
  # Agents
  case ${1:-agents} in *agents* )
    sdproc "$ME file agents" "visDQM.*Daemon|visDQM.*Castor.*|visDQMIndex|zip" ;;
  esac
  # Server
  case ${1:-webserver} in *webserver* )
    sdproc "$ME webserver" "[/]monGui $CFGDIR" ;;
  esac
  # Part of the server are the render processes
  case ${1:-renderer} in *renderer* )
    sdproc "$ME renderer" "visDQMRender" ;;
  esac
  # Extra thing to check: loggers
  case ${1:-logger} in *logger* )
    sdproc "$ME loggers" "rotatelogs" ;;
  esac
}

# (Re)compile render plugins.
compile()
{
  for CONFIG in $CONFIGS; do
    monControl rebuild all from $CFGDIR/server-conf-$CONFIG.py
  done
}

# Backup index to castor
# The backup is incremental, with a full backup at regular intervals
indexbackup()
{
  refuseproc "castor index backup" "visDQMIndexCastorStager"

  for D in $CONFIGS; do
    D=${D}
    # Set default CASTOR directory to a testing area. Only the production
    # servers (Offline and Relval and Dev) get the real thing.
    case $HOST:$D in
      vocms0131:dev | vocms0138:offline | vocms0139:relval )
        CASTORDIR=/castor/cern.ch/cms/store/dqm/ixbackup/$D
        ;;
      * )
        CASTORDIR=/castor/cern.ch/cms/store/dqm/testing/ixbackup/$D
        ;;
    esac
    # We run the backup everywhere when the backup method is called,
    # except for the offline and relval flavor on the dev server.
    case $HOST:$D in
      vocms0131:offline | vocms0131:relval )
	;;
      * )
        DQM_DATA=$STATEDIR/$D
        LOGSTEM=$D/agent-castorindexbackup
        # Start the process not as an agent, but directly in the current thread.
        # It is supposed to be started from/by acrontab on regular intervals (like 15 mins).
        # The backup is incremental, but we do a full backup every 50 days.
        visDQMIndexCastorStager \
          $DQM_DATA/agents/ixstageout \
          $DQM_DATA/ix128 \
          $CASTORDIR \
          broen.van.besien@cern.ch,marco.rovere@cern.ch \
          --fullbackup 50 \
          </dev/null 2>&1 | rotatelogs $LOGDIR/$LOGSTEM-%Y%m%d.log 86400 >/dev/null 2>&1
      esac
  done
}

# Backup new root files (zipped) to castor
zipbackup()
{
  refuseproc "castor root file backup" "visDQMZipCastorStager"

  for D in $CONFIGS; do
    D=${D}
    # Set default CASTOR directory to a testing area. Only the production
    # servers (Offline and Relval and Dev) get the real thing.
    case $HOST:$D in
      vocms0131:dev | vocms0138:offline | vocms0139:relval )
        CASTORDIR=/castor/cern.ch/cms/store/dqm/data/$D
        ;;
      * )
        CASTORDIR=/castor/cern.ch/cms/store/dqm/testing/data/$D
        ;;
    esac
    # We run the backup everywhere when the backup method is called,
    # except for the offline and relval flavor on the dev server.
    case $HOST:$D in
      vocms0131:offline | vocms0131:relval )
	;;
      * )
        DQM_DATA=$STATEDIR/$D
        LOGSTEM=$D/agent-castorzipbackup
        # Start the process not as an agent, but directly in the current thread.
        # It is supposed to be started from/by acrontab on regular intervals (like 15 mins).
        visDQMZipCastorStager \
          $DQM_DATA/agents/stageout \
          $DQM_DATA/zipped \
          $CASTORDIR \
          $DQM_DATA/agents/verify \
          </dev/null 2>&1 | rotatelogs $LOGDIR/$LOGSTEM-%Y%m%d.log 86400 >/dev/null 2>&1
    esac
  done
}

# Check / verify the backup of the zipped root files to castor
zipbackupcheck()
{
  refuseproc "castor root file backup check" "visDQMZipCastorVerifier"

  for D in $CONFIGS; do
    D=${D}
    # Set default CASTOR directory to a testing area. Only the production
    # servers (Offline and Relval and Dev) get the real thing.
    case $HOST:$D in
      vocms0131:dev | vocms0138:offline | vocms0139:relval )
        CASTORDIR=/castor/cern.ch/cms/store/dqm/data/$D
        ;;
      * )
        CASTORDIR=/castor/cern.ch/cms/store/dqm/testing/data/$D
        ;;
    esac
    # We run the backup everywhere when the backup method is called,
    # except for the offline and relval flavor on the dev server.
    case $HOST:$D in
      vocms0131:offline | vocms0131:relval )
	;;
      * )
        DQM_DATA=$STATEDIR/$D
        LOGSTEM=$D/agent-castorzipbackupcheck
        # Start the original agent process, however, not as an agent, but directly in the current thread.
        # The agent was modified in such a way that it exits after each cycle.
        # It is supposed to be started from/by acrontab.
        visDQMZipCastorVerifier \
          $DQM_DATA/agents/verify \
          broen.van.besien@cern.ch,marco.rovere@cern.ch \
          $DQM_DATA/zipped \
          $CASTORDIR \
          24 \
          $DQM_DATA/agents/clean \
          </dev/null 2>&1 | rotatelogs $LOGDIR/$LOGSTEM-%Y%m%d.log 86400 >/dev/null 2>&1
    esac
  done
}

# Verify the security string.
check()
{
  CHECK=$(echo "$1" | md5sum | awk '{print $1}')
  if [ $CHECK != 94e261a5a70785552d34a65068819993 ]; then
    echo "$0: cannot complete operation, please check documentation." 1>&2
    exit 2;
  fi
}

# Main routine, perform action requested on command line.
while [ $# -ge 1 ]; do
  case $1 in
    -q ) QUIET=true; shift ;;
    -f ) FLAVOR=$2; shift;shift;;
    -h ) set -- help ;;
    -- ) shift; break ;;
    -* ) echo "$0: unrecognised option '$1'" 1>&2; exit 1;;
    *  ) break ;;
  esac
done
newline=""
getconfigs

# Checking the user name:
# If the $ALTERNATIVE_USER is set, then
# - indexbackup, zipbackup and zipbackupcheck must run as the $ALTERNATIVE_USER
# - all the rest is not allowed to run as the $ALTERNATIVE_USER.
CURRENT_USER=$(id -un)
if [ -n "$ALTERNATIVE_USER" ]; then
  case $1 in
    indexbackup | zipbackup | zipbackupcheck )
      if [ "$CURRENT_USER" != "$ALTERNATIVE_USER" ]; then
        echo "ERROR: Trying to start $1 as normal user, use ALTERNATIVE_USER instead." 1>&2
        exit 1
      fi ;;
    * )
      if [ "$CURRENT_USER" = "$ALTERNATIVE_USER" ]; then
        echo "ERROR: Trying to run as ALTERNATIVE_USER, use normal user instead." 1>&2
        exit 1
      fi ;;
  esac
fi

case ${1:-status} in
  sysboot )
    sysboot
    ;;

  start | restart )
    check "$2"
    stop
    start
    ;;

  status )
    status
    ;;

  dstatus )
    detailstatus
    ;;

  stop )
    check "$2"
    stop
    ;;

  compile )
    compile
    ;;

  xstart | xrestart )
    check "$3"
    stop "$2"
    start "$2"
    ;;

  xstatus)
    status "$2"
    ;;

  xdstatus )
    detailstatus "$2"
    ;;

  xstop )
    check "$3"
    stop "$2"
    ;;

  indexbackup )
    check "$2"
    indexbackup
    ;;

  zipbackup )
    check "$2"
    zipbackup
    ;;

  zipbackupcheck )
    check "$2"
    zipbackupcheck
    ;;

  help )
    perl -ne '/^##H/ && do { s/^##H ?//; print }' < $0
    ;;

  version )
    echo "$DQMGUI_VERSION"
    ;;

  * )
    echo "$0: unknown action '$1', please try '$0 help' or documentation." 1>&2
    exit 1
    ;;
esac
